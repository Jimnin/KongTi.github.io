---
title: 딥러닝을 위한 수학(1)
date: 2023-01-30 18:00:00 GMT+0900
categories: [공부, 통계]
tags: [통계] # TAG names should always be lowercase
math: true
---

<img src="https://image.yes24.com/goods/111086874/XL" width="400px" title="book">

# <center>1장</center>

## T-test (T 검정)

### 4장에서 다시 한번 언급하며 공부할 예정 $\rightarrow$ 간단하게 이해하고 넘어가자

- ### <strong>두 데이터 집합의 평균이 같은지 판정</strong>
- ### <strong>p-value</strong>: 귀무 가설(null hypothesis)이 맞다는 전제 하에, 표본에서 실제로 관측된 통계치와 '같거나 더 극단적인' 통계치가 관측될 확률

  - 즉, p-value가 낮다면 두 집단이 통계적으로 같지않다는 것을 뜻함
  - 보통 0.05의 값을 boundary로 지정하지만 해석에 따라 다르게 지정할 수 있다

- ### "두 데이터 집합이 동일한 과정으로 생성되었음을 얼마나 강하게 믿을 수 있나?"
- ### 1sample t-test는 표본과 모집단의 비교, 2sample t-test는 표본1과 표본2의 비교
- ### scipy 라이브러리를 이용하여 stats 모듈의 ttest_ind로 구현 가능

numpy을 이용하여 정규분포를 따르는 랜덤 추출

```python
a = np.random.normal(0,1,1000)
b = np.random.normal(0,0.5,1000)
c = np.random.normal(0.1,1,1000)
```

각 집합에 대한 평균을 구하기 (mean)

```python
-0.010454382967016595
-0.003513559049901122
0.08494838783591534
```

scipy의 T-검정 실행

```python
ttest_ind(a,b)
statistic=-0.19717619348410984, pvalue=0.8437097152433868

ttest_ind(a,c)
statistic=-2.15582710436493, pvalue=0.03121622339162003
```

a집단과 b집단은 통계적으로 비슷한 환경에서 생성 됐지만, c집단과는 다를 가능성이 높다.

---

# <center>2장</center>

## 표본공간 (Sample Space)

### 모든 가능한 결과 (outcome)를 나타내는 이산 집합 / 연속 구간

- 사건 (Event): 뭔가가 발생하는 것, 과정의 결과
- 표본 (Sample): 표본 공간에서 뽑은 하나의 사건

### <center>딥러닝에선 대부분의 표본 공간이 연속적이다</center>

<p style="color:red;text-align:center">Why?<br/>실수의 범위로 입력이 들어오면서, Weight Sum의 계산 과정이 존재하기 때문</p>

<img src="https://www.math.net/img/a/probability-and-statistics/inferential-statistics/sample-space/ss.svg" title="samplespace">

## 이산 확률 변수 (Discrete random variable)

### 동전 던지기와 같은 결과는 표본 공간 자체가 이산적인 형태를 보이기 때문에 이산 확률 변수로 나타낼 수 있다. 즉, 동전이 앞이 나올 확률이 50%의 <strong>특정한 확률을 갖게 되는 특징</strong>

$$
\begin{aligned}
  & P(X=앞면)=P(X=뒷면)=0.5
\end{aligned}
$$

<center>여기서, X는 확률 변수(random variable)이라고 부르며, 사건의 결과를 나타내며,<br/>P는 괄호 안에 있는 주어진 확률 변수가 해당 결과를 취할 확률을 나타낸다.</center>

## 연속 확률 변수 (Continuous random variable)

### 정규 분포처럼 표본 공간이 연속적이며, X가 아닌 $$x$$로 표기한다.

<img src="https://images.nagwa.com/figures/explainers/504196353149/1.svg" title="crv">

재미있는게 이산 확률 변수처럼 특정한 확률을 가지게 아니기 때문에, a부터 b까지의 <strong>적분을 통해 확률을 구하는데 그러면 특정한 곳에서 가지는 확률은 0이 된다</strong> (면적이 나오지 않기 때문)

## 확률에 대한 재미있는 사례 (작성 중)

- ### [몬티 홀 딜레마](#확률에-대한-재미있는-사례-작성-중)
- ### [암 진단의 정확성](#확률에-대한-재미있는-사례-작성-중)
- ### [생일의 역설](#확률에-대한-재미있는-사례-작성-중)

## 확률의 합과 곱의 법칙

### 두 사건 A와 B가 <strong>동시에 일어날 수 없을 때</strong>, 상호 배반 (mutually exclusive)이라고 한다

- 예를 들면, 동전이 앞면과 뒷면 함께 나오지 않는 경우

### 또한, <strong>A의 확률이 B에 영향을 받지 않으면</strong> 서로 독립 (independent)라고 한다

<br/>

$$
\begin{aligned}
  & P(A 또는 B)=P(A\cup B)=P(A)+P(B)
\end{aligned}
$$

<center><strong>상호 배반적인 사건</strong>에 대해서 위와 같은 <strong>합의 법칙</strong>을 적용할 수 있다.</center>

$$
\begin{aligned}
  & P(A 또는 B)=P(A)+P(B)-P(A 그리고 B)
\end{aligned}
$$

<center><strong>상호 배반적인 아닌 사건</strong>이라면 <strong>수정 합의 법칙</strong>을 적용한다.</center>

<br/>

$$
\begin{aligned}
  & P(A 그리고 B)=P(A\cap B)=P(A)P(B)
\end{aligned}
$$

<center><strong>서로 독립 사건</strong>에 대해서는 위의 <strong>곱의 법칙</strong>을 적용할 수 있다.</center>

## 조건부 확률 (Conditional probability)

<img src="https://i.stack.imgur.com/93Y1t.png" title="conditional">

### 사건 A가 발생했을 때, 사건 B가 <strong>영향을 받아 확률이 변하면</strong> 조건부 확률이 발동한다.

<br/>

$$
\begin{aligned}
  & P(A 그리고 B)=P(B|A)P(A)
\end{aligned}
$$

<center><strong>서로 독립이 아니라면 조건부 확률의 곱의 법칙</strong>을 적용하게 된다.</center>

### 표본 공간을 다수의 서로소 영역 $$B_i(B_1,B_2,...)$$로 나눈다면 합은 표본 공간 전체가 된다.

<center>(서로소는 공통된 요소가 없는 영역, 영역이 겹치지 않음)</center>

<br/>

$$
\begin{aligned}
  & P(A)={\underset{i}{\Sigma}}P(A|B_i)P(B_i)
\end{aligned}
$$

즉, 여기서는 $$B_i$$사건이 발생했을 때, $$A$$의 사건이 발생할 조건부 확률을 나타낸다. 그리고 $$P(A)$$는 분할 $$B_i$$들에 관한 $$A$$의 전체 확률이라고 부른다. 간단하게 밑의 그림으로 이해할 수 있을 것이라 생각된다.

<img src="https://blog.kakaocdn.net/dn/blhbEn/btqXZJfBcp7/Gk24rAt8KtA3QQv53YZugK/img.png" title="total">

## 결합확률 (Joint probability)

### $$P(X=x, Y=y)$$는 $$X$$의 값이 $$x$$임과 동시에 $$Y$$의 값이 $$y$$일 확률

- 즉, 결합확률은 여러가지의 조건이 동시에 만족될 (참인) 확률이다.
- $$P(A 그리고 B)=P(A\cap B)$$ 형태로 나타낸다.

## 주변확률 (Marginal probability)

### 하나 이상의 조건이 참일 확률, 다시 말해 코딩의 "or"과 비슷한거 같다

## 결합 확률표

### 여러가지 확률들은 '결합 확률표'를 그리면 쉽게 도출할 수 있다

$$X$$는 성적이고, $$Y$$는 최종학력을 나타내는 결합 확률표의 예시이다.
<img src="https://blog.kakaocdn.net/dn/yYdft/btqBVLfTpEe/jLWctDL0TLREYxjKJmUS4K/img.png" title="table">

- 조사에 응한 사람이 총 100명이라고 가정하자
- $$X=보통, Y=대졸$$ 인 결합확률은 0.18로 18명이며,
- $$X=우수$$ 인 주변확률은 총합으로 45명인 것을 유추할 수 있다.

## 확률의 연쇄법칙

### 셋 이상의 확률 변수를 연쇄법칙을 이용하여 확장할 수 있다

미분의 Chain Rule과 같은 방법으로 일반형을 만들 수 있다.

$$
\begin{aligned}
  & P(X_n, X_{n-1}..., X_1)=\overset{n}{\underset{i=1}{\Pi}}P(X_i|\overset{i-1}{\underset{j=1}{\cap}}X_j)
\end{aligned}
$$

쉽게 예를 들면 $$P(X, Y, Z)=P(X|Y, Z)P(Y, Z)=P(X|Y, Z)P(Y|Z)P(Z)$$인데
<br/>Z가 발생할 확률, Z가 발생했을 때 Y가 발생할 확률, Y, Z가 발생했을 때 X가 발생할 확률을 곱한 것

<br/>

4개의 확률 변수에 대해서도 똑같이 적용할 수 있다.

$$
\begin{aligned}
  & \\ P(A, B, C, D)=P(A|B, C, D)P(B, C, D)
  \\=P(A|B, C, D)P(B|C, D)P(C, D)
  \\=P(A|B, C, D)P(B|C, D)P(C|D)P(D)
\end{aligned}
$$

예를 들어 50명의 사람이 참석한 곳에서 미국을 다녀온 사람이 4명이라고 가정할 때, 무작위로 3명을 뽑았을 때 아무도 미국에 간 적이 없을 확률은?

사람 한명을 뽑을 수록 다음 한명을 뽑을 때 전체 인원이 줄어들기 때문에 조건부 확률을 적용한다

$$
\begin{aligned}
  & P(A, B, C)=P(A|B, C)P(B|C)P(C)=(\frac{44}{48})(\frac{45}{49})(\frac{46}{50})
\end{aligned}
$$

수식으로는 0.7745로 77.45%가 나오는데 실제로도 그럴까?? 코드로...

```python
nb = 0
N = 100000 # 시행횟수
for i in range(N):
  s = np.random.randint(0,50,3) # 0-49까지에서 3개를 무작위로 뽑는다
  fail = False
  for t in range(3):
    if (s[t] < 4): # 뽑은 수에서 4보다 작으면 미국을 갔다고 가정한다
      fail = True
  if (not fail):
    nb += 1
print(f"확률은 {nb/N*100}%")
```

확률은 77.81%정도 나오는데 얼추 비슷한 값이 나오는 것으로 보아 수식이 옳다고 말할 수 있다.

[Github 코드](<https://github.com/KongTi/Study/blob/main/딥러닝을위한수학/딥러닝을위한수학(1).ipynb>)
